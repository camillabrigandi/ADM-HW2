{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29048312-3d37-4a16-9511-11e7a109bc1d",
   "metadata": {},
   "source": [
    "# Question Bounes 1)\n",
    "\n",
    "## 1.1)\n",
    "## Using PySpark\n",
    "\n",
    "I first installed PySpark by:\n",
    "$ pip install pyspark\n",
    "\n",
    "- Then, used 'SparkSession.builder.appName(\"FilterAuthors\").getOrCreate()' to create a Spark session in order to use its built-in libraries and methods.\n",
    "- I read the json file with '.read.json()' method. PySpark is basically designed to work with Big data.\n",
    "- Pyspark uses resilient distributed datasets (RDDs) to work parallel on the data. Hence, it performs better than pandas.\n",
    "- PySpark uses lazy processing, retrieving data from disk only when required, while the pandas module stores all data in memory, resulting in higher memory consumption compared to PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45c2a7a2-e916-4b29-9372-265ec7319e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+------------------+\n",
      "|     id|           name|text_reviews_count|\n",
      "+-------+---------------+------------------+\n",
      "|   3389|   Stephen King|            608956|\n",
      "|1077326|   J.K. Rowling|            606373|\n",
      "| 153394|Suzanne Collins|            427224|\n",
      "| 150038|Cassandra Clare|            416177|\n",
      "|3433047|  Sarah J. Maas|            372923|\n",
      "+-------+---------------+------------------+\n",
      "\n",
      "CPU times: user 38.1 ms, sys: 11.3 ms, total: 49.5 ms\n",
      "Wall time: 2.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"FilterAuthors\").getOrCreate()\n",
    "\n",
    "# Read the JSON file\n",
    "df = spark.read.json(\"lighter_authors.json\")\n",
    "\n",
    "# Filter the DataFrame based on the text_reviews_count property\n",
    "filtered_df = df.filter(col(\"text_reviews_count\") >= 100)\n",
    "\n",
    "# Sort the DataFrame in descending order by 'text_reviews_count'\n",
    "sorted_df = filtered_df.sort(col(\"text_reviews_count\").desc())\n",
    "\n",
    "# Select specific columns and return the first 5 rows\n",
    "result_df = sorted_df.select(\"id\", \"name\", \"text_reviews_count\").limit(5)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "result_df.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54054f-0cff-4c0b-80fb-9db605b71e55",
   "metadata": {},
   "source": [
    "## Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58308309-c33d-4952-ab02-29a7ac3c442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id             name  text_reviews_count\n",
      "1017       3389     Stephen King              608956\n",
      "86500   1077326     J.K. Rowling              606373\n",
      "27522    153394  Suzanne Collins              427224\n",
      "27110    150038  Cassandra Clare              416177\n",
      "157593  3433047    Sarah J. Maas              372923\n",
      "CPU times: user 23.2 s, sys: 1.93 s, total: 25.1 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "\n",
    "authors_json = pd.read_json('./lighter_authors.json', lines = True, chunksize=100)\n",
    "\n",
    "authors_df = pd.concat(authors_json, ignore_index=False)\n",
    "\n",
    "# Filter the DataFrame based on 'text_reviews_count'\n",
    "filtered_df = authors_df[authors_df['text_reviews_count'] >= 100]\n",
    "\n",
    "# Sort the filtered DataFrame in descending order by 'text_reviews_count'\n",
    "sorted_df = filtered_df.sort_values(by='text_reviews_count', ascending=False)\n",
    "\n",
    "# Select specific columns and return the first 5 rows\n",
    "result_df = sorted_df[['id', 'name', 'text_reviews_count']].head(5)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43729860-3d57-4ce4-aa32-4b32dd01d8ca",
   "metadata": {},
   "source": [
    "## Compare the performance of PySpark Vs Pandas:\n",
    "\n",
    "| Library     | CPU user    | sys         | total       | Wall time   | \n",
    "| ----------- | ----------- | ----------- | ----------- | ----------- |\n",
    "| PySpark | 38.1 ms | 11.3 ms | 49.5 | 2.61 |\n",
    "| Pandas | 23.2 s | 1.93  | 25.1 s | 25.1 s |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ecc9d-6802-47a2-af3c-eba86399d586",
   "metadata": {},
   "source": [
    "## 1.2)\n",
    "\n",
    "### First approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c45a22d0-3005-4c78-936f-d36605bd4746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"JoinBooksAndAuthors\").getOrCreate()\n",
    "\n",
    "# Read the 'lighter_books.json' and 'lighter_authors.json' files\n",
    "books_df = spark.read.json(\"lighter_books.json\")\n",
    "authors_df = spark.read.json(\"lighter_authors.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d3a9d4d-3067-43e7-b4e7-24ef1815bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in 'lighter_books.json': ['asin', 'author_id', 'author_name', 'authors', 'average_rating', 'description', 'edition_information', 'format', 'id', 'image_url', 'isbn', 'isbn13', 'language', 'num_pages', 'original_publication_date', 'publication_date', 'publisher', 'rating_dist', 'ratings_count', 'series_id', 'series_name', 'series_position', 'shelves', 'text_reviews_count', 'title', 'work_id']\n",
      "------------------------------------------------------------\n",
      "Columns in 'lighter_authors.json': ['about', 'average_rating', 'book_ids', 'fans_count', 'gender', 'id', 'image_url', 'name', 'ratings_count', 'text_reviews_count', 'work_ids', 'works_count']\n"
     ]
    }
   ],
   "source": [
    "# Get the column names for each DataFrame for better understanding of the structure of datasets.\n",
    "books_columns = books_df.columns\n",
    "authors_columns = authors_df.columns\n",
    "\n",
    "# Print the column names\n",
    "print(\"Columns in 'lighter_books.json':\", books_columns)\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Columns in 'lighter_authors.json':\", authors_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3274faa-2377-4b73-a31d-b52f40aab448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of books without a matching author: 0\n"
     ]
    }
   ],
   "source": [
    "# Perform the join operation. books with the same author_id as authors with the same id, will be joined together.   \n",
    "joined_df = books_df.join(authors_df, books_df['author_id'] == authors_df['id'], 'left_outer')\n",
    "\n",
    "# Count the number of books without a matching author\n",
    "books_without_author = joined_df.filter(authors_df['id'].isNull()).count()\n",
    "\n",
    "# Count the number of books that couldn't be joined\n",
    "unjoined_count = joined_df.filter(authors_df['id'].isNull()).count()\n",
    "\n",
    "# Show the count\n",
    "print(f\"Number of books that could not be joined: {unjoined_count}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b0922-0cac-470c-bfa7-392cf67277d1",
   "metadata": {},
   "source": [
    "### Second approach\n",
    "\n",
    "In this approach, \n",
    "- first, we return the number of rows in lighter_books.json. which is stored in 'num_rows_books'.\n",
    "- Then, we define a variable named 'joined_df_count' as an incrementation. if any row of lighter_books.json and any row of lighter_authors.json were be joint, increase 'joined_df_count' for 1. or basically calculate the count of joined_df.\n",
    "- Then, we return the difference between the 'joined_df_count' and number of rows from the books.json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac128a1c-0c9b-4e25-97b0-dafa646b1142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/31 12:26:03 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows in lighter_books.json: 7027431\n",
      "Value of 'joined_df_count': 7027431\n",
      "Difference: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"JoinAndCount\").getOrCreate()\n",
    "\n",
    "# Read 'lighter_books.json' and 'lighter_authors.json'\n",
    "books_df = spark.read.json(\"lighter_books.json\")\n",
    "authors_df = spark.read.json(\"lighter_authors.json\")\n",
    "\n",
    "# Join the two DataFrames based on 'author_id' and 'id'\n",
    "joined_df = books_df.join(authors_df, books_df['author_id'] == authors_df['id'], 'inner')\n",
    "\n",
    "# Calculate the number of rows in 'lighter_books.json'\n",
    "num_rows_books = books_df.count()\n",
    "\n",
    "# Define and increment the variable 'k' for each matching row\n",
    "joined_df_count = joined_df.count()\n",
    "\n",
    "# Calculate the difference between 'k' and the number of rows in 'lighter_books.json'\n",
    "difference = joined_df_count - num_rows_books\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of Rows in lighter_books.json:\", num_rows_books)\n",
    "print(\"Value of 'joined_df_count':\", joined_df_count)\n",
    "print(\"Difference:\", difference)\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7614eb-b6b9-4a28-b9d2-38e521048bf0",
   "metadata": {},
   "source": [
    "### conclusion:\n",
    "As can be seen, all books have an id that exists in authors.json file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d3d39-be5d-42b7-9c06-ad49d28e9b6c",
   "metadata": {},
   "source": [
    "# Question Bounes 2)\n",
    "\n",
    "## 2.1) & 2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f201ece-6d75-448d-bbfc-23afdf289f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------------+\n",
      "| id|                name|          genre|\n",
      "+---+--------------------+---------------+\n",
      "|  4|       Douglas Adams|        Romance|\n",
      "|  7|         Bill Bryson|    Non-Fiction|\n",
      "| 10|         Jude Fisher|        Fantasy|\n",
      "| 12|James Hamilton-Pa...|    Non-Fiction|\n",
      "| 14|         Mark Watson|         Comedy|\n",
      "| 16|       Edith Wharton|        Romance|\n",
      "| 17|       Luther Butler|        Romance|\n",
      "| 18|        Gary Paulsen|        Romance|\n",
      "| 20|           Dale Peck|       Children|\n",
      "| 23|       Angela Knight|        Romance|\n",
      "| 24|       Delia Sherman|        Fantasy|\n",
      "| 25|Patricia A. McKillip|        Romance|\n",
      "| 26|      Anne McCaffrey|Science Fiction|\n",
      "| 27|Zilpha Keatley Sn...|       Children|\n",
      "| 29|        Kate Horsley|        Romance|\n",
      "| 31|   Elaine Cunningham|        Fantasy|\n",
      "| 32|       Philippa Carr|     Historical|\n",
      "| 33|     Edward P. Jones|       Children|\n",
      "| 36|        Satyajit Das|           NULL|\n",
      "| 38|         Mark Smylie|        Fantasy|\n",
      "+---+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+--------------------+---------------+\n",
      "| id|               title|          genre|\n",
      "+---+--------------------+---------------+\n",
      "|  2|Harry Potter and ...|        Fantasy|\n",
      "|  3|Harry Potter and ...|        Romance|\n",
      "|  4|Harry Potter and ...|         Horror|\n",
      "|  5|Harry Potter and ...|        Fantasy|\n",
      "|  6|Harry Potter and ...|        Fantasy|\n",
      "|  7|The Harry Potter ...|        Mystery|\n",
      "|  8|Harry Potter Boxe...|           NULL|\n",
      "| 10|Harry Potter Coll...|        Mystery|\n",
      "| 11|The Hitchhiker's ...|Science Fiction|\n",
      "| 12|The Ultimate Hitc...|Science Fiction|\n",
      "| 13|The Ultimate Hitc...|Science Fiction|\n",
      "| 14|The Hitchhiker's ...|Science Fiction|\n",
      "| 15|The Hitchhiker's ...|      Adventure|\n",
      "| 16|The Hitchhiker's ...|Science Fiction|\n",
      "| 17|The Hitchhiker's ...|           NULL|\n",
      "| 18|The Ultimate Hitc...|Science Fiction|\n",
      "| 19|The Hitchhiker's ...|        Romance|\n",
      "| 21|A Short History o...|    Non-Fiction|\n",
      "| 22|Bill Bryson's Afr...|      Adventure|\n",
      "| 23|Bryson's Dictiona...|      Adventure|\n",
      "+---+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"GroupAuthorsIntoGenres\").getOrCreate()\n",
    "\n",
    "# Read 'lighter_authors.json' and 'lighter_books.json'\n",
    "authors_df = spark.read.json(\"lighter_authors.json\")\n",
    "books_df = spark.read.json(\"lighter_books.json\")\n",
    "\n",
    "# Define triggers for genres\n",
    "genre_triggers = {\n",
    "    \"Romance\": [\"love\", \"relationship\", \"heart\", \"passion\", \"kiss\", \"romantic\", \"affection\"],\n",
    "    \"Mystery\": [\"mystery\", \"detective\", \"crime\", \"suspense\", \"puzzle\", \"enigma\", \"whodunit\"],\n",
    "    \"Fantasy\": [\"fantasy\", \"magic\", \"kingdom\", \"mythical\", \"enchanted\", \"magical\"],\n",
    "    \"Science Fiction\": [\"science fiction\", \"space\", \"alien\", \"future\", \"technology\", \"extraterrestrial\"],\n",
    "    \"Non-Fiction\": [\"non-fiction\", \"memoir\", \"history\", \"biography\", \"documentary\", \"autobiography\"],\n",
    "    \"Adventure\": [\"adventure\", \"quest\", \"journey\", \"exploration\", \"excitement\", \"expedition\"],\n",
    "    \"Horror\": [\"horror\", \"scary\", \"fear\", \"terror\", \"supernatural\", \"haunting\"],\n",
    "    \"Comedy\": [\"comedy\", \"funny\", \"humor\", \"laughter\", \"comic\", \"hilarious\"],\n",
    "    \"Drama\": [\"drama\", \"tragedy\", \"emotional\", \"theatre\", \"intense\", \"performing\"],\n",
    "    \"Thriller\": [\"thriller\", \"suspenseful\", \"intense\", \"nail-biting\", \"tension\", \"exciting\"],\n",
    "    \"Biography\": [\"biography\", \"life story\", \"autobiography\", \"history\", \"memoir\", \"personal journey\"],\n",
    "    \"Fantasy\": [\"fantasy\", \"magic\", \"kingdom\", \"mythical\", \"enchanted\", \"magical\"],\n",
    "    \"Science Fiction\": [\"science fiction\", \"space\", \"alien\", \"future\", \"technology\", \"extraterrestrial\"],\n",
    "    \"Historical\": [\"historical\", \"period\", \"past\", \"epoch\", \"history\", \"retro\"],\n",
    "    \"Self-Help\": [\"self-help\", \"personal growth\", \"motivation\", \"positive\", \"self-improvement\", \"inspiration\"],\n",
    "    \"Cooking\": [\"cooking\", \"culinary\", \"recipes\", \"food\", \"chef\", \"cuisine\"],\n",
    "    \"Travel\": [\"travel\", \"adventure\", \"exploration\", \"journey\", \"destination\", \"vacation\"],\n",
    "    \"Science\": [\"science\", \"scientific\", \"discovery\", \"research\", \"knowledge\", \"experiment\"],\n",
    "    \"Children\": [\"children\", \"kids\", \"juvenile\", \"childhood\", \"youth\", \"picture book\"],\n",
    "    \"Poetry\": [\"poetry\", \"verse\", \"rhyme\", \"lyrical\", \"poem\", \"stanza\"],\n",
    "}\n",
    "\n",
    "# Define a UDF to assign genres based on triggers.\n",
    "# The UDF assign_genre iterates through the genre_triggers dictionary.\n",
    "# For each genre, it iterates through the list of triggers associated with that genre.\n",
    "# It checks if any of these triggers (converted to lowercase for case-insensitive matching) are found in the 'about' text of the author.\n",
    "# If a trigger is found in the 'about' text, the UDF returns the associated genre.\n",
    "def assign_genre(text):\n",
    "    for genre, triggers in genre_triggers.items():\n",
    "        for trigger in triggers:\n",
    "            if trigger in text.lower():\n",
    "                return genre\n",
    "    return None\n",
    "\n",
    "# Register the UDF with Spark\n",
    "assign_genre_udf = udf(assign_genre, StringType())\n",
    "\n",
    "# Create a new column 'genre' based on the 'about' field\n",
    "authors_df = authors_df.withColumn(\"genre\", when(col(\"about\").isNotNull(), assign_genre_udf(col(\"about\"))).otherwise(None))\n",
    "\n",
    "# Create a new column 'genre' based on the 'description' field\n",
    "books_df = books_df.withColumn(\"genre\", when(col(\"description\").isNotNull(), assign_genre_udf(col(\"description\"))).otherwise(None))\n",
    "\n",
    "# Select and show the resulting DataFrame with 'id', 'name', and 'genre' columns\n",
    "result_authors_df = authors_df.select(\"id\", \"name\", \"genre\")\n",
    "result_authors_df.show()\n",
    "\n",
    "# Select and show the resulting DataFrame with 'id', 'title', and 'genre' columns\n",
    "result_books_df = books_df.select(\"id\", \"title\", \"genre\")\n",
    "result_books_df.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b0afea-ede8-40c1-8448-ac15e2bd55f2",
   "metadata": {},
   "source": [
    "## 2.3)\n",
    "\n",
    "As can be seen, if we increase the number of triggers for genres, the accuracy of dedicating of a genre would be higher.\n",
    "- After reading two datasets using PySpart, we defined an Object with some key value pairs. the keys are the geners that we want to dedicate to each book or author's description or about part. the values are the list of words that we search for them in the description and the about text.\n",
    "- then, we defined a User-Defined Function (UDF) to assign genres to authors and books based on certain \"triggers\" found in their 'about' and 'description' text.\n",
    "- A UDF is a way to define a custom function that can be applied to the columns of a PySpark DataFrame.\n",
    "- Then, We add a new column to the authors and books datafram, and wrote down the genres.\n",
    "- The same approach works fine for both of the frameworks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
